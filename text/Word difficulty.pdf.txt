Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications, pages 84–94,

San Diego, California, June 16, 2016. c(cid:13)2016 Association for Computational Linguistics

84

CharacterizingTextDifﬁcultywithWordFrequenciesXiaobinChen∗andDetmarMeurersLEADGraduateSchoolDepartmentofLinguisticsEberhardKarlsUniversit¨atT¨ubingen{xiaobin.chen,detmar.meurers}@uni-tuebingen.deAbstractNaturallanguageprocessing(NLP)method-ologieshavebeenwidelyadoptedforreadabil-ityassessmentandgreatlyenhancedpredic-tiveaccuracy.Inthepresentstudy,westudyawell-establishedfeature,thefrequencyofawordincommonlanguageuse,andsystemat-icallyexplorehowsuchaword-levelfeatureisbestusedtocharacterizethereadinglev-elsoftexts,atext-levelclassiﬁcationproblem.Whiletraditionallysuchword-levelfeaturesaresimplyaveragedforallwordsofgiventext,weshowthataricherrepresentationleadstosigniﬁcantlybetterpredictivemodels.Abasicapproachaddingafeatureforthestandarddeviationalreadyshowscleargains,andtwomorecomplexoptionssystematicallyintegratingmorefrequencyinformationareexplored:(i)encodingseparatemeansforthewordsofatextaccordingtowhichfre-quencybandofthelanguagetheyoccurin,and(ii)encodingthemeanofeachclusterofwordsobtainedbyagglomerativehierarchicalclusteringofthewordsinthetextbasedontheirfrequency.Theformerorganizesfre-quencyaroundgenerallanguagecharacteris-tics,whereasthelatteraimstoloseaslittleinformationaspossibleaboutthedistributionofwordfrequenciesinagiventext.Toin-vestigatethegeneralizabilityoftheresults,wecomparecross-validationexperimentswithinacorpuswithcross-corpusexperimentstest-ingontheCommonCoreStateStandardsref-erencetexts.Wealsocontrasttwodifferentfrequencynormsandcomparefrequencywithameasureofcontextualdiversity.∗XiaobinChenisalsoafﬁliatedwiththeSouthChinaUniversityofTechnology,whereheholdsalecturerposition.1IntroductionAlthoughreadabilityresearchhasgonethroughahistoryofmorethanonehundredyears(DuBay,2007),theuseofNaturalLanguageProcessing(NLP)technologyinreadabilityresearchisarecentphenomenon.Ithasgreatlyimprovedthepredictiveaccuracybyenablingamulti-dimensionalcharac-terizationofatext’sreadinglevel(Benjamin,2012;Collins-Thompson,2014).Forexample,VajjalaandMeurers(2012)showedthat46lexicalandsyntac-ticfeaturesmostlyinspiredbycomplexitymeasuresSecondLanguageAcquisitionresearchsupportaclassiﬁcationaccuracyof91.3%onWeeklyReader,acollectionoftextstargetingchildreninfouragegroupscommonlyusedinsuchreadabilityresearch(PetersenandOstendorf,2009;Fengetal.,2010).Thereadabilityofatextisdeterminedbythecom-binationofalltextaspectsthataffectsthereader’sunderstanding,readingspeed,andlevelofinterestinthetext(DaleandChall,1949).Recentstudiesex-plorelexical,morphological,semantic,psycholin-guistic,syntactic,andcognitivefeaturesfordeter-miningthereadinglevelsoftexts(Crossleyetal.,2007;Luetal.,2014;Hanckeetal.,2012;Bostonetal.,2008;vorderBr¨ucketal.,2008;Heilmanetal.,2007;Feng,2010;McNamaraetal.,2014).Amongalltheseelements,thesemanticvariableofworddifﬁcultyhastraditionallybeenfoundtoac-countforthegreatestpercentageofreadabilityvari-ance(Marksetal.,1974).Worddifﬁcultyisof-tenassociatedwithwordfrequencygiventhattheamountofexposureofareadertothewordisbe-lievedtobethemajorpredictorofwordknowl-edge(RyderandSlater,1988).85

Inthepresentstudy,wezoomintothequestionhowwordfrequencycanbestbeusedtocharacterizethereadabilityofatext.Weexperimentedwiththreedifferentmethodsofusingfrequencyasaword-levelfeaturetoinformourpredictionsofreadabilityatthetext-level.2TheFrequencyEffectReadingisacoordinatedexecutionofaseriesofpro-cesseswhichinvolvewordencoding,lexicalaccess,assigningsemanticroles,andrelatingtheinforma-tioncontainedinasentencetoearliersentencesinthesametextandthereader’spriorknowledge(JustandCarpenter,1980).Successfulcomprehensionoftextsdependsonthereaders’semanticandsyntac-ticencodingabilities(Marksetal.,1974),aswellastheirvocabularyknowledgeinthelanguage(LauferandRavenhorst-Kalovski,2010;Nation,2006).Ageneralconsensusofreadingresearchisthatlexicalcoverage/vocabularyknowledgearegoodpredictorsofreadingcomprehension(BernhardtandKamil,1995;Laufer,1992;Nation,2001;Nation,2006;Qian,1999;Qian,2002;UlijnandStrother,1990).Areader’svocabularyknowledgeislargelyre-latedtotheamountofexposuretheyhavereceivedtowords—oftenreferedtoasfrequencyeffect.Itisarguedtobepredictiveofworddifﬁculty(RyderandSlater,1988)andLeroyandKauchak(2014)foundthatwordfrequencyisstronglyassociatedwithbothactualdifﬁculty(howwellpeoplecanchoosethecorrectdeﬁnitionoftheword)andper-ceiveddifﬁculty(howdifﬁcultawordlooks).High-frequencywordsareusuallyperceivedandpro-ducedmorequicklyandmoreefﬁcientlythanlow-frequencyones(BalotaandChumbley,1984;HowesandSolomon,1951;JescheniakandLevelt,1994;Monselletal.,1989;RaynerandDuffy,1986).Con-sequently,atextwithmanyhigh-frequencywordsisgenerallyeasiertounderstandthanonewithanum-berofrarewords.Frequencyofwordoccurrenceaffectsnotonlytheeaseofreading,butalsoitsac-ceptability(Klare,1968).Thefrequencyeffectisbasedonacognitivemodelassumingahigherbase-levelofactivationforfrequently-usedwords,sotheyrequirerelativelylessadditionalactivationwhentheyarebeingre-trievedfromthereader’smentallexicon(JustandCarpenter,1980).Thisideaissupportedbytheﬁnd-ingsthathigh-frequencywordsaremoreeasilyper-ceived(BrickerandChapanis,1953)andreadilyre-trievedbythereader(Haseley,1957).Goingbe-yondthisbasiceffect,infrequency-basedaccountsofSecondLanguageAcquisition(Ellis,2012),thefrequencydistributionoftheinputisakeydeter-minantofacquisition,withregularitiesemergingthroughthelearner’sexposuretothedistributionalcharacteristicsofthelanguageinput.3WordFrequencyforReadabilityAssessmentFigure1illustrateshowwordfrequencycanbelinkedtoreadingcomprehension.Basedonamodelsuchasthisone,itisreasonabletoassumethatlexi-calfrequenciescaninformtext-levelanalyses.Figure1:ThefrequencyeffectonreadingcomprehensionTraditionalreadabilityformulasusedmeasuressuchasnumberof“zero-indexwords”(numberofwordsthatarenotincludedinthemostfre-quentwordsinEnglish),medianofindexnum-bers(LivelyandPressey,1923),averagewordweightedvalue(PattyandPainter,1931),ornum-berofwordsfromthetextthatareamongtheﬁrst1,000andﬁrst2,000mostfrequentwords(Ojemann,1934)forpredictingreadinglevels.Thesemeasureswerefoundtobehighlycorrelatedwithdifﬁcultyandeffectiveinassessingtextreadability.ModernreadabilityassessmentsystemssuchasLexile(Lexile,2007),ATOS(MiloneandBiemiller,2014),andCohMetrix(McNamaraetal.,2014)alsomadewideuseofwordfrequenciestohelpdeter-minethereadinglevelofatext,andsuchsystems86

werefoundtoberelativelyeffective(Nelsonetal.,2012).However,thereareseveralissuesconcerningthefrequencylistsused,thenatureofthefrequencymeasures,andhowtheyareusedtoaccountfortextreadabilitythatdeservemoreattention.Theﬁrstissueisthatthefrequencylistsadoptedbythesestudiesweremostlydrawnfromwrittencorpora.Spokenlanguagewasrarelytakenintoconsiderationwhenfrequencylistswerebeingcom-posed.Thisrunstheriskofthefrequencyvaluesnotbeingafaithfulrepresentationofthereader’sac-tuallanguageexperience,hencebeingsuboptimalforpredictingtheeaseofperceptionandretrieval.Fortunately,theSUBTLEXfrequencylists(Brys-baertandNew,2009;vanHeuvenetal.,2014)havebeencompiledonthebasisofspokenlanguagedatadrawnfrommovieandTVsubtitlestoobtainmorefaithfulrepresentationsofalanguagetypicaluser’sexperiencewithlanguage.TheSUBTLEXfrequencylistssigniﬁcantlybetterpredictwordpro-cessingtimesthanearliernormssuchasKuˇceraandFrancis(1967)andCelex(Baayenetal.,1993),orfrequenciesnormsderivedfromthehugeGooglebookscorpus(cf.Brysbaertetal.,2011).Thesecondissueconcernshowfrequencyismea-sured.Previousresearchgenerallysumsupalloc-currencesofawordinthecorpus.Yetsomewordsmaybefrequentinrestrictedcontextsbutarenotfre-quentwhenconsideringallcontextsoflanguageuse.AsarguedbyAdelmanetal.(2006),abettermethodmaybetocounttheContextualDiversity(CD),thenumberofcontextsinwhichawordoccurs.TheyfoundtheCDmeasuretobeabetterpredictorofwordfrequencyeffectsinlexicaldecisiontasks,amethodforprobingintothewordknowledgeinthespeaker’smentallexicon.However,tothebestofourknowledge,CDmeasureshaveneverbeentestedintext-levelreadabilityassessment.Toaddressthisgap,weexperimentedwithbothfrequencyandCDmeasuresinconstructingourreadabilitymodels.Finally,asforhowtousewordfrequenciesforbuildingreadabilitypredictionmodels,previousre-searchtypicallyemployedmeanfrequenciesorthepercentageofwordsfromthetopfrequencybandstocharacterizetextlevels.Yet,thislosesalotofin-formationaboutthedistributionofwordfrequenciesinthetext.Averagingiseasilyaffectedbyextremevalues,anditlosesinformationaboutthevariabil-ityofthedata.Furthermore,averagingoveralloc-currencesofwordsinatextwillminimizethecon-tributionoflow-frequencywords—yet,itmaybepreciselytheseless-frequentwordsthatarecausingreadingdifﬁculties.Inordertoexplorehowwordfrequencycanbebetterusedforreadabilityassess-ment,wetestthreedifferentmethodsforcharacter-izingtextsintermsoflexicalfrequency:(i)comple-mentingthemeanfrequencywiththestandardde-viation,(ii)encodingseparatemeansforthewordsofatextaccordingtowhichfrequencybandofthelanguagetheyoccurin,and(iii)encodingthemeanofeachclusterofwordsobtainedbyagglomera-tivehierarchicalclusteringofthewordsinthetextbasedontheirfrequency.Thesecondmethodor-ganizesthefrequencymeasuresaroundgenerallan-guagecharacteristics,whereasthethirdoneaimstoloseaslittleinformationaspossibleaboutthedis-tributionofwordfrequenciesinagiventext.Thegoaloftheseriesofexperimentsistoidentifybettermethodsforcharacterizingtextsofdifferentreadinglevelsfromthelexicalperspective.Insum,thereviewsofthefrequencyeffectonreadingcomprehensionandearlierresearchontheuseofwordfrequencyforreadabilityassessmentsupportthehypothesisthatalexicalfrequencymea-surereﬂectingthereader’slanguageexperiencecanplayasubstantialroleinmodelsoftextreadability.Theresearchreportedhereisdevotedtotestingthishypothesisinawaythataddressesthethreeprob-lemsspelledoutabove:thesourceofthefrequencylist,thenatureofthefrequencymeasureused,andthemethodforcombiningword-levelevidencefortext-levelpredictions.4ExperimentalSetupBeforeturningtothethreeexperimentscarriedout,letusintroducetheresourcesandthegeneralpro-cedureused.AssourceofthefrequencyandCD1information,weusedtheSUBTLEXus(BrysbaertandNew,2009)andtheSUBTLEXuk(vanHeuvenetal.,2014)resources.Weranallexperimentswithtwodistinctfrequencyresourcestobeabletostudytheimpactofthechoiceofresource.Ascorpusforexploringtheapproachand10-foldcrossvalidation1TheCDmeasureweusedisreferredtoasSUBTLCDinSUBTLEXusandasCDinSUBTLEXuk.87

testingweusedtheleveledtextcorpusWeeBit(Va-jjalaandMeurers,2012).Forindependentcross-corpustesting,wetrainedonWeeBitandtestedontheexemplartextsfromAppendixBoftheCommonCoreStateStandards(CommonCore,2010).Formachinelearning,weusedthebasick-nearestneigh-boralgorithmimplementedintheRpackageclassgiventhatinourinitialexplorationitturnedouttoperformonaparorbetterthanothercommonlyusedalgorithmssuchasSupportVectorMachineorDe-cisionTrees.4.1TheSUBTLEXListsTheSUBTLEXus(BrysbaertandNew,2009)con-tains74,286wordformswithfrequencyvaluescal-culatedfroma51-million-wordcorpusofsubti-tlesfrom8,388Americanﬁlmsandtelevisionse-riesbroadcastbetween1900and2007.TheSUB-TLEXuk(vanHeuvenetal.,2014)istheBritishcounterpart,consistingof160,022wordformswithfrequencyvaluescalculatedfroma201.7-million-wordcorpusofsubtitlesfromnineBritishTVchan-nelsbroadcastbetweenJanuary2010andDecem-ber2012.TheSUBTLEXresourcesprovidefre-quencyinformationinseveralformsmotivatedinvanHeuvenetal.(2014);wemadeuseofthefre-quenciesgivenontheZipfscale(log10ofthefre-quencyperbillionwords),aswellastheCDvalues,forwhicheachﬁlmorTVprogramcountedasacon-text.4.2TheWeeBitandCommonCoreCorporaTheWeeBitcorpususedinanumberofreadabilityandtextsimpliﬁcationstudies(VajjalaandMeurers,2012;VajjalaandMeurers,2013;VajjalaandMeur-ers,2014)wascollectedfromtheeducationalmag-azineWeeklyReaderusedinearlierreadabilityre-search(PetersenandOstendorf,2009;Fengetal.,2010)andtheBBC-Bitesizewebsite.Assumma-rizedinTable1,itisa789,926-wordcorpusoftextslabeledwithﬁvegradereadinglevels.TheCommonCorecorpusconsistsofexemplartextsfromAppendixBoftheEnglishLanguageArtsStandardsoftheCommonCoreStateStandards.ThecorpusweusefortestinginourexperimentsisexactlythesameastheoneusedbyNelsonetal.(2012).Theyeliminatedthelowest(K–1)leveloftheoriginalsixlevelsandremovedrepetition,dra-GradeLevelAgeGroup#Articles#Words/ArticleWRLevel27–8616152.63WRLevel38–9616190.74WRLevel49–10616294.91BiteSizeKS311–14616243.56BiteSizeGCSE14–16616400.51Table1:DetailsoftheWeeBitcorpusmas,andtextsintendedforteachertoreadaloud,resultingin168remainingpassagesatﬁvelevels.4.3ExperimentalProcedureThefollowingbasicprocedurewasfollowedforeachoftheexperimentscarriedout:1.TokenizecorpustextswithCoreNLPTok-enizer(Manningetal.,2014),whichhadalsobeenusedtocomposetheSUBTLEXfre-quencylists.2.Characterizeeachtextusingfrequencyfea-tures.Thenatureofthefeaturesdiffersacrossthethreestudies,forwhichdetailsaregiveninthefollowingsections.3.TrainclassiﬁcationmodelsontheWeeBitcor-pusi)ina10-foldCross-Validation(CV)setuporii)usingthefullcorpuswhentheCommonCoredatawasusedastest.TheK-nearestneighborsalgorithmoftheRpackageclasswasusedformodelconstructionandtesting.4.Applythetrainedmodeltothetestfoldsortestcorpustoassessmodelperformance.5.ReportresultsintermsofSpearman’scorrela-tioncoefﬁcient(ρ)toallowcomparisonofCVandcross-corpusresults.Wereportboth10-foldCVperformanceonWeeBitandthetestperformanceonCommonCoreasreferencesformodelﬁtandgeneralizability.TheKNNalgorithmresultsindifferentmodelswhentheparameterKissetdifferently.TheparameterKforeachmodelwasdecidedautomaticallybytestingKfromoneuptothesquarerootofthenumberoftextsusedfortrainingandchoosingthevaluethatresultedinthebestperformingmodel.Inthispaper,wereporttheperformanceofthebestmodels.88

ThecompleteprogramforfeatureextractionandexperimentsettingswithRcodecanbeobtainedfromhttp://xiaobin.ch.5Study1:AddingStandardDeviationInthisﬁrststudy,wetriedthemostconservativeex-tension:inadditiontothemeanfrequenciesofthewordsinagivendocument,wecomputedthestan-darddeviation(SD).Sowecompared+SDmodelstrainedontwofrequencyfeatures(meanandSD)withthebaseline−SDmodelstrainedonlyonthemeanfrequency.Asexplainedintheprevioussec-tion,wetestedthisusingtheZipfandCDmea-suresfromtwodifferentfrequencyresources,SUB-TLEXusandSUBTLEXuk.Weexperimentedwithbothtokenandtypemodels.Fortokenmodels,weconsideredtheSUBTLEX-frequencyofeachwordinstanceinagiventext.Fortypemodels,eachdistinctwordinthedocumentwasconsideredonlyonce.Table2sumsuptheresultsforthe10-foldCVintermsoftheSpearmanrankcorrelationρbetweenmodel-predictedandactualreadinglevelsoftexts.2Table3showstheperformanceofthemodelstrainedonWeeBitandtestedonCommonCore.TokenType−SD+SD−SD+SDUS-ZIPF-.02.40∗∗∗.26∗∗.42∗∗∗US-CD-.02.46∗∗∗.19∗.44∗∗∗UK-ZIPF.05.25∗∗∗.31∗∗∗.38∗∗∗UK-CD.04.26∗∗∗.21∗∗.29∗∗∗Table2:10-foldCVresultsformodelswithout/withSDTokenType−SD+SD−SD+SDUS-ZIPF.03.34∗∗∗.33∗∗∗.35∗∗∗US-CD-.27∗∗∗.28∗∗∗.22∗∗.33∗∗∗UK-ZIPF-.13.26∗∗∗.36∗∗∗.38∗∗∗UK-CD.00.02.33∗∗∗.27∗∗∗Table3:CommonCoretestresultswithout/withSDThemodelstrainedonfrequencymeanandSDsystematicallyperformedbetterthanthosetrained2Hereandthroughout,wemarksigniﬁcantdifferences(fromthenullhypothesisthatthereisnocorrelation)with***forp≤.001,**forp≤.01,and*forp≤.05.withonlymeanfrequencies.WhileconsideringbothmeanandSDofwordfrequenciesseemslikeanob-viouschoice,asfarasweknownopreviousresearchmadeuseofthisoptionprovidingsigniﬁcantlybet-terperformancefortext-levelreadabilityprediction.Theresultsalsoshowthatthetypemodelsuni-formlyoutperformthetokenmodels.Inordertofurtherexplorethisﬁnding,inFigure2weplottedTokenType4.55.05.56.01234512345LevelMean Zipf ValueFigure2:Meantokenvs.typeZipfbyCommonCoretextlevelthemeantokenandtypefrequenciesofthewordsineachtextoftheCommonCorecorpusbytextlevel.Asthereadinglevelincreases,theplotshowsaclearpatternofdecreasingmeantypeZipfvalues.Thisisnotobservableforthetokenaverages.High-frequencytokensusuallyhavemultipleoc-currenceinagiventext,inﬂatingthesumoffre-quencyvaluesandobscuringtheinﬂuenceoflowfrequencywordsonthemean.Thetype-basedmea-sureeliminatesmultipleoccurrencesoftokenssothatwordsacrossthefrequencyspectrumcontributeequally.ThefactthattheaveragetypefrequenciesinFigure2aresoclearlyassociatedwiththeread-abilitylevelstransparentlysupportsthefrequencyeffect.Comparingtheresultsbasedonfrequency(Zipf)withthoseusingContextualDiversity(CD),dif-ferentfromthelexicaldecisiontasks(BrysbaertandNew,2009),whereCDwasmorepredictive,fortext-levelreadabilityassessment,frequencyper-formsbetterforreadabilityassessment.Finally,Table3alsoshowcasesthatfrequencylistscalculatedfromdifferentcorpora(here:SUB-TLEXusvs.SUBTLEXuk)doresultinsubstantially89

differentmodelperformance.Forexample,theZipfmeasurefromtheSUBTLEXuscorpusresultedinthebetter10-foldCVperformancethanthatfromtheSUBTLEXukcorpus,withahighlysigniﬁcantSpearman’scorrelationcoefﬁcient(ρ=.42,p≤.001)forthetypemodel.6Study2:MeanFrequenciesofWordsfromLanguageFrequencyBandsForthesecondstudy,frequencymeans3ofwordsfromstratiﬁedfrequencylistswerecalculatedandusedasfeaturestocharacterizethetexts’readinglevels.Tostratifythefrequencylist,thewordsintheSUBTLEXlistswereorderedbytheirfrequencyvalues.Thenthelistwascutintoanumberoffre-quencybands,resultingineachwordbeingassignedabandnumber.Wordsinthesamebandthusoc-curwithsimilarfrequencyinthelanguageasrep-resentedbythecorporatheSUBTLEXlistswerecompiledfrom.Thewordsinagiventexttobean-alyzedarematchedwiththewordsinthefrequencylistandgroupedbythewords’bandnumbers.Thetextcanthenbecharacterizedbytheaveragefre-quenciesofthewordsineachband,i.e.,weobtainoneaverageperband.WithbothSUBTLEXlists,weexperimentedwithupto100bands.Asbefore,weusedtheZipffrequencyandCDmeasuresandtestedbothtokenandtypemodels.Figures3and4showtheperformanceoftokenandtypesmodelstrainedwithfeaturesfromboththeSUBTLEXlists.Theperformanceisgivenintermsof10-foldCVρsandcross-corpusρstestedonCommonCore.UnliketheresultsofStudy1,thetokenmodelsdidnotperformsigniﬁcantlydifferentfromthetypemodelsfor10-foldCV.However,thetypemodelsgeneralizedbettertotheCommonCoretestsetthanthetokenmodels.Wordtypefrequencythusbettercapturesthefrequencycharacteristicsofatext.Forreadabilityassessmentpurposes,calcu-latingmeantypefrequencyofwordsfromeachfre-quencybandcreatesbetterpredictionmodels.AcomparisonoftheresultswiththosefromStudy1showsthatthemodelsconstructedusingthestratiﬁcationmethodclearlyoutperformedthosefromStudy1usingonlyasinglemeanforallwords.WhentheZipfmeasurefromtheUSlistisstratiﬁed3WithoutSD;addingSDdidnotimproveperformance.into60bands,thetrainedmodelhasthebestper-formanceamongallthemodels,reachinga10-foldCVρ=.83,p≤.001andacross-corpustestingρ=.39,p≤.001).Performanceonthetestsetisrathervolatile,though:whenthelistwascutinto20bands,theresultingmodelfailedtodistinguishbe-tweentextlevels(ρ=−.11,p≥.05)forthetestcorpus,whilethewith-incorpusCVcorrelationco-efﬁcientwasρ=.80,p≤.001.Themethodusedinthisstudythusneedstobeﬁne-tunedwithrespecttothecorporaorresourcesathandtoachievetheoptimalresults.7Study3:FrequencyClusterMeansTheideabehindthethirdstudyisthefollowing:Therichestfrequencyrepresentationofatextwouldbeavectorofthefrequencyofallwordsinthetext.Butthisistooﬁnegrainedtobedirectlycompara-bleacrosstexts,andtextsalsodifferinlength.4Wethereforeincrementallygroupwordstogetherthatdifferminimallyintermsoftheirfrequencyvalues.Wecanthencomputetheaveragefrequenciesofthewordsineachgroup.Torealizethisidea,weusedagglomerativehierarchicalclusteringtoconstructawordfrequencyhierarchicalclustertreeforeachtextinthetrainingcorpus.Concretely,weusedthehclust()functioninRwiththedefaultcompletelinkagemethodandthedist()functionforcalcu-latingEuclideandistancesasdissimilaritystructureforhclust().Thetreeswerethencutatdifferentdistancesfromtheroottoobtainanincreasingnumberofbranches,witheachbranchrepresentingthesetofwordsclos-estinfrequency.Thebranchmeans5werecalculatedforeachsetandusedasfeaturestoconstructthepre-dictionmodels.WeexperimentedwiththeZipfmeasurefromtheSUBTLEXusfrequencylistwithupto100clustersandexploredtypeandtokenmodels.Theperfor-manceofthetrainedmodelsareshowninFigure5.4Orthogonaltothenumberoffrequencyvaluescompared,notethattheorderofwordsinagiventextisignoredhere.Theordermaywellproviderelevantinformationcharacterizingthereadabilityofatext.Forexample,asimpletextmaywellin-cluderarewordsaslongastheyarefollowedbymorefrequentwordsexplainingtherareones.Thiscouldbeinterestingtoex-ploreinfuturework.5WithoutSD;addingSDdidnotimprovemodelperfor-manceeither.90

CDZIPF0.00.20.40.60.80.00.20.40.60.8Token modelsType models02550751000255075100Number of bandsSpearman's rhorhoWithin-corpusCross-corpusFigure3:10-foldCVandcross-corpustestρsbetweenpredictedandactualtextreadinglevelsbynumberofSUBTLEXusbandsCDZIPF0.00.50.00.5Token modelsType models02550751000255075100Number of bandsSpearman's rhorho10-fold CVCross-corpusFigure4:10-foldCVandcross-corpustestρsbetweenpredictedandactualtextreadinglevelsbynumberofSUBTLEXukbands91

ZIPF_VALUE0.00.20.40.60.00.20.40.6Token modelsType models0255075100Number of clustersSpearman's rhorho10-fold CVCross-corpusFigure5:10-foldCVandcross-corpustestingρsbetweenpredictedandactualtextreadinglevelsbynumberofclustersFormostcuttingschemes,thetokenandtypemod-elsperformedcomparably.Asthenumberofclus-terincreased,thetrainedmodelsimprovedinperfor-mance,withthetestingρspeakingat70clustersforallmodels.Table4providestheinformationforthebestperformingmodelsfromthisstudy.ModelType#ClustersρTokenModel10-foldCV85.74***Cross-corpus70.49***TypeModel10-foldCV85.74***Cross-corpus71.49***Table4:Best-performingmodelsfromclusteringexperimentThemodelsconstructedinthisexperimentsper-formedsigniﬁcantlybetterthanthosefromStudy1.AlthoughthemodelsfromStudy2hadhigherCVρs,thosefromthisstudyshowamorestablecross-corpustestingperformance,whichisofmajorim-portanceforusingsuchamethodinpractice.Itisstrikingthatclusteringthewordsinatextthataresimilarinwordfrequencyismorereliableacrosscorporathangroupingwordsbythelanguagefre-quencybandsasageneralcharacteristicoflanguageindependentofthetexts.8ComparisonwithPreviousWorkNelsonetal.(2012)assessedthecapabilitiesofsixtoolsforpredictingtextdifﬁculty:thecom-mercialsystemsLexile(MetaMetrics),ATOS(Re-naissanceLearning),DRPAnalyzer(QuestarAs-sessment,Inc.),thePearsonReadingMaturityMet-ric(PearsonKnowledgeTechnologies),SourceRater(EducationalTestingService),andtheresearchsys-temREAP(CarnegieMellonUniversity).Wordfre-quencyisameasurethatisincludedinallthesesys-tems,thoughallofthemincorporateadditionalfea-turessuchassyntacticcomplexity.Oneoftheeval-uationsreportedbyNelsonetal.(2012)wascar-riedoutonthefreelyavailableCommonCoreexem-plartextsthatwasalsousedinVajjalaandMeurers(2014)andthepresentresearch,andtheyreportedSpearman’sρ,makingtheirresultscomparabletoours.Theresultsreportedforthebestsystemsclearly92

highlightthevalueofrichfeaturesets,reaching.76forSourceRaterand.69forReadingMaturity,whichisalsothelevelreachedbytheVajjalaandMeurers(2014)model.Atthesametime,theapproachbasedsolelyonfrequencywediscussedinStudy3withaρof.50isonaparwiththeresultsnotedbyNelsonetal.(2012)fortheLexilesystem,andonlyslightlyworsethanthe.53reportedforDRP.Thecomparisonthusclearlyconﬁrmstherele-vanceofconsideringhowlexicalfrequencyinforma-tionistobeintegratedintoreadabilityassessment.9ConclusionsInthispaper,weexploredthetextreadabilityanal-ysisfromaword-levelperspective,zoominginonlexicalfrequency.Thegoalofthethreeexperimentscarriedoutintheresearchwastoinvestigatehowatext-levelclassiﬁcationproblemcanbeinformedbyaword-levelfeatureofthetext,namelythefre-quencyofwordsingenerallanguageuse.Wordfre-quencyisrelatedtothedifﬁcultylevelofatextgiventhatreadingcomprehensionispartiallydeterminedbythereader’svocabularyknowledge,whichinturnisrelatedtowordfrequency.Thefrequencyeffectofvocabularyonthereadinglevelsoftextisinlinewithabasiccognitivemodelpositingthatwordsofhigherfrequencieshaveahigherlevelofactivationandrequirelessextraeffortwhentheyarebeingre-trievedfromthereader’smentallexicon.Asare-sult,wherefrequencylistsfaithfullyrepresentthereader’slanguageexperience,theycanpredicthowdifﬁcultthewordsusedinatextaretothereaderandinturninformestimatesofthereadabilityofthetext.Threemethodsofusingwordfrequencyliststopredicttextreadabilityweretestedandconﬁrmedthatwordfrequencyiseffectiveincharacterizingtextdifﬁculty,especiallywhenmorethanjusttheav-eragefrequencyofthewordsinatextistakenintoaccount.Characterizingtextreadabilityintermsoftheoverallmeanandstandarddeviationofwordfre-quenciesperformedbetterthanmodelsjustusingthemean.Themodelbasedonthefrequenciesofthewordtypesoccurringinthetext(ratherthantheto-kens)werebetterthroughoutandgeneralizedmuchbetteracrosscorpora.Intermsofthenatureofthemeasureitself,themodelstrainedwiththeZipffre-quencymeasureswerefoundtooutperformthosebasedonmeasuresofContextualDiversity.ThemodelstrainedwithstratiﬁedfrequencymeasuresinthesecondstudyshowedthebestperformancefortheCVevaluationusingasinglecorpus,butgener-alizedlesswelltotheratherdifferenttestdatasetbasedontheCommonCoretextsthantheclusteringapproachexploredinthethirdstudy.Withrespecttoapplyingthesemethodsinprac-ticalreadabilityassessmentcontexts,theZipffre-quencymeasuresfromtheSUBTLEXfrequencylistsseemtobewell-suited,withtheoverallmeanfrequencyandSDvaluescomputedbasedonthewordtypesbeingeasyandeffective.Thestratiﬁca-tionmethodimprovesperformanceoverthesimplemeanandSD,butitrequiresﬁne-tuningofthenum-berofbands.Theclusteringmethodhasthebestmodelperformanceandisleastsensitivetotheuseofdifferentfrequencylistsandmeasures,butitisalsocomputationallythemostexpensive.Whiletheperformanceofthebestfrequencymodelsreachesalevelthatiscompetitivewithsys-temssuchasLexile,clearlyacomprehensiveap-proachtoreadabilityassessmentwillintegrateabroadrangeoffeaturesintegratingmoreaspectsofthelinguisticsystem,languageuse,andhumanlan-guageprocessing.Wheretextsarecharacterizedintermsofobservationsofsmallerunits,basedourresultsforlexicalfrequencyitwillbeadvisabletocharacterizetextlevelreadabilitybymorethansim-plemeanswhenaggregatingtheinformationob-tained,e.g.,atthelexicalorsentencelevel.AcknowledgmentsThisresearchwasfundedbytheLEADGraduateSchool[GSC1028],aprojectoftheExcellenceIni-tiativeoftheGermanfederalandstategovernments.XiaobinChenisadoctoralstudentattheLEADGraduateSchool.ReferencesJamesS.Adelman,GordonD.A.Brown,andJos´e.F.Quesada.2006.Contextualdiversity,notwordfre-quency,determineswordnamingandlexicaldecisiontimes.PsychologicalScience,17(9):814–23.93

R.HaraldBaayen,RichardPiepenbrock,andH.vanRijn.1993.Thecelexlexicaldatabase.CD-ROM.DavidA.BalotaandJamesI.Chumbley.1984.Arelex-icaldecisionsagoodmeasureoflexicalaccess?Theroleofwordfrequencyintheneglecteddecisionstage.JournalofExperimentalPsychology:HumanPercep-tion&Performance,10(3):340–357.RebekahGeorgeBenjamin.2012.Reconstructingread-ability:recentdevelopmentsandrecommendationsintheanalysisoftextdifﬁculty.EducationalPsychologyReview,24(1):63–88.ElizabethB.BernhardtandMichaelL.Kamil.1995.In-terpretingrelationshipsbetweenL1andL2reading:Consolidatingthelinguisticthresholdandthelinguis-ticinterdependencehypotheses.AppliedLinguistics,16(1):15–34.MarisaFerraraBoston,JohnHale,ReinholdKliegl,UmeshPatil,andShravanVasishth.2008.Parsingcostsaspredictorsofreadingdifﬁculty:AnevaluationusingthePotsdamSentenceCorpus.JournalofEyeMovementResearch,2(1):1–12.PeterD.BrickerandAlphonseChapanis.1953.Doin-correctlyperceivedstimuliconveysomeinformation?PsychologicalReview,60(3):181–188.MarcBrysbaertandBorisNew.2009.MovingbeyondKuˇceraandFrancis:AcriticalevaluationofcurrentwordfrequencynormsandtheintroductionofanewandimprovedwordfrequencymeasureforAmericanEnglish.BehaviorResearchMethods,41(4):977–990.MarcBrysbaert,EmmanuelKeuleers,andBorisNew.2011.AssessingtheusefulnessofGoogleBooks’wordfrequenciesforpsycholinguisticre-searchonwordprocessing.FrontiersinPsychology,2(March):1–8.KevynCollins-Thompson.2014.Computationalassess-mentoftextreadability:Asurveyofpast,present,andfutureresearch.InternationalJournalofAppliedLin-guistics,165(2):97–135.CommonCore.2010.CommonCoreStateStandardsforEnglishLanguageArtsandLiteracyinHistory/SocialStudies,Science,andTechnicalSubjects.CommonCoreStateStandardsInitiative.ScottCrossley,DavidDufty,PhilipMcCarthy,andDanielleMcNamara.2007.Towardanewreadabil-ity:Amixedmodelapproach.InProceedingsofthe29thannualconferenceoftheCognitiveScienceSoci-ety,pages197–202,Nashville,Tennessee,USA.EdgarDaleandJeanneChall.1949.Theconceptofread-ability.ElementaryEnglish,26(1):19–26.WilliamH.DuBay.2007.UnlockingLanguage:TheClassicReadabilityStudies.BookSurgePublishing.NickC.Ellis.2012.Frequency-basedaccountsofSLA.InSusanM.GassandAlisonMackey,editors,Hand-bookofSecondLanguageAcquisition,pages193–210.Routledge.LijunFeng,MartinJansche,MattHuenerfauth,andNomieElhadad.2010.Acomparisonoffeaturesforautomaticreadabilityassessment.InInProceedingsofthe23rdInternationalConferenceonComputationalLinguistics(COLING2010),Beijing,China.LijunFeng.2010.AutomaticReadabilityAssessment.Doctoraldissertation,TheCityUniversityofNewYork.JuliaHancke,SowmyaVajjala,andDetmarMeurers.2012.ReadabilityclassiﬁcationforGermanusinglexical,syntactic,andmorphologicalfeatures.InProceedingsofthe24thInternationalConferenceonComputationalLinguistics(COLING2012),pages1063–1080,Mumbai,India.LeonardHaseley.1957.Therelationshipbetweencue-valueofwordsandtheirfrequencyofprioroccur-rence.Unpublishedmaster’sthesis,Ohiouniversity.MichaelJ.Heilman,KevynCollins-Thompson,JamieCallan,andMaxineEskenazi.2007.Combininglexicalandgrammaticalfeaturestoimprovereadabil-itymeasuresforﬁrstandsecondlanguagetexts.InProceedingsofNAACLHLT2007,pages460–467,Rochester,NY.AssociationforComputationalLin-guistics.DowesH.HowesandRichardL.Solomon.1951.Visualdurationthresholdasafunctionofword-probability.JournalofExperimentalPsychology,41(6):401–410.J¨orgD.JescheniakandWillemJ.M.Levelt.1994.Wordfrequencyeffectsinspeechproduction:Retrievalofsyntacticinformationandofphonologicalform.Jour-nalofExperimentalPsychology:Learning,Memory,&Cognition,20(4):824–843.MarcelAdamJustandPatriciaA.Carpenter.1980.Atheoryofreading:Fromeyeﬁxationstocomprehen-sion.Psychologicalreview,87(4):329–354.GeorgeR.Klare.1968.Theroleofwordfrequencyinreadability.ElementaryEnglish,45(1):12–22.HenryKuˇceraandW.NelsonFrancisFrancis.1967.ComputationalAnalysisofPresent-dayEnglish.BrownUniversityPress,Providence,RI.BatiaLauferandGekeRavenhorst-Kalovski.2010.Lexicalthresholdrevisited:Lexicaltextcoverage,learners’vocabularysizeandreadingcomprehension.ReadinginaForeignLanguage,22(1):15–30.BatiaLaufer.1992.Howmuchlexisisnecessaryforreadingcomprehension?InH.BejointandP.Arnaud,editors,Vocabularyandappliedlinguistics,pages126–132.Macmillan,Basingstoke&London.GondyLeroyandDavidKauchak.2014.Theeffectofwordfamiliarityonactualandperceivedtextdifﬁculty.JournaloftheAmericanMedicalInformaticsAssocia-tion,21(e1):1–4.94

Lexile.2007.TheLexileFrameworkforreading:The-oreticalFrameworkandDevelopment.Technicalre-port,MetaMetrics,Inc.,Durham,NC.BerthaA.LivelyandSidneyL.Pressey.1923.Amethodformeasuringthevocabularyburdenoftextbooks.Ed-ucationalAdministrationandSupervision,9:389–398.XiaofeiLu,Davida.Gamson,andSarahAnneEckert.2014.LexicaldifﬁcultyanddiversityofAmericanel-ementaryschoolreadingtextbooks:Changesoverthepastcentury.InternationalJournalofCorpusLinguis-tics,19(1):94–117.ChristopherDManning,MihaiSurdeanu,JohnBauer,JennyFinkel,StevenJBethard,andDavidMcClosky.2014.TheStanfordCoreNLPNaturalLanguagePro-cessingToolkit.InProceedingsof52ndAnnualMeet-ingoftheAssociationforComputationalLinguistics:SystemDemonstrations,pages55–60.CarolynB.Marks,MarleenJ.Doctorow,andM.C.Wittrock.1974.Wordfrequencyandreadingcom-prehension.TheJournalofEducationalResearch,67(6):259–262.DanielleS.McNamara,ArthurC.Graesser,PhilipM.McCarthy,andZhiqiangCai.2014.AutomatedEval-uationofTextandDiscoursewithCoh-Metrix.Cam-bridgeUniversityPress,NewYork,NY.MichaelMiloneandAndrewBiemiller.2014.Thede-velopmentofATOS:TheRenaissancereadabilityfor-mula.Technicalreport,RenaissanceLearning,Wis-consinRapids.S.Monsell,M.C.Doyle,andP.N.Haggard.1989.Ef-fectsoffrequencyonvisualwordrecognitiontasks:Wherearethey?JournalofExperimentalPsychol-ogy:General,118(1):43–71.I.S.PaulNation.2001.Learningvocabularyinanotherlanguage.CambridgeUniversityPress,Cambridge.I.S.PaulNation.2006.Howlargeavocabularyisneededforreadingandlistening?TheCanadianMod-ernLanguageReview,63(1):59–82.JessicaNelson,CharlesPerfetti,DavidLiben,andMeredithLiben.2012.Measuresoftextdifﬁculty:Testingtheirpredictivevalueforgradelevelsandstu-dentperformance.Technicalreport,TheGatesFoun-dation.RalphJ.Ojemann.1934.Thereadingabilityofparentsandfactorsassociatedwithreadingdifﬁcultyofpar-enteducationmaterials.UniversityofIowaStudiesinChildWelfare,8:11–32.WillardW.PattyandW.I.Painter.1931.Atechniqueformeasuringthevocabularyburdenoftextbooks.Jour-nalofEducationalResearch,24(2):127–134.SarahE.PetersenandMariOstendorf.2009.Amachinelearningapproachtoreadinglevelassessment.Com-puterSpeechandLanguage,23:86–106.DavidQian.1999.Assessingtherolesofdepthandbreadthofvocabularyknowledgeinreadingcompre-hension.TheCanadianModernLanguageReview,56(2):282–308.DavidQian.2002.Investigatingtherelationshipbe-tweenvocabularyknowledgeandacademicreadingperformance:Anassessmentperspective.LanguageLearning,52(3):513–536.KeithRaynerandSusanA.Duffy.1986.Lexicalcom-plexityandﬁxationtimesinreading:Effectsofwordfrequency,verbcomplexity,andlexicalambiguity.Memory&Cognition,14(3):191–201.RandallJamesRyderandWayneH.Slater.1988.Therelationshipbetweenwordfrequencyandwordknowledge.TheJournalofEducationalResearch,81(5):312–317.JanM.UlijnandJudithB.Strother.1990.TheeffectofsyntacticsimpliﬁcationonreadingESTtextsasL1andL2.JournalofResearchinReading,13(1):38–54.SowmyaVajjalaandDetmarMeurers.2012.Onimprov-ingtheaccuracyofreadabilityclassiﬁcationusingin-sightsfromsecondlanguageacquisition.InProceed-ingsoftheSeventhWorkshoponBuildingEducationalApplicationsUsingNLP,pages163–173,Montr´eal,Canada.AssociationforComputationalLinguistics.SowmyaVajjalaandDetmarMeurers.2013.OntheapplicabilityofreadabilitymodelstoWebtexts.InProceedingsofThe2ndWorkshoponPredictingandImprovingTextReadabilityforTargetReaderPopu-lations,pages59–68,Soﬁa,Bulgaria.AssociationforComputationalLinguistics.SowmyaVajjalaandDetmarMeurers.2014.Read-abilityassessmentfortextsimpliﬁcation:Fromana-lyzingdocumentstoidentifyingsententialsimpliﬁca-tions.InternationalJournalofAppliedLinguistics,165(2):194–222.WalterJ.B.vanHeuven,PawelMandera,EmmanuelKeuleers,andMarcBrysbaert.2014.SUBTLEX-UK:AnewandimprovedwordfrequencydatabaseforBritishEnglish.TheQuarterlyJournalofExperimen-talPsychology,67(6):1176–90.TimvorderBr¨uck,SvenHartrumpf,andHermannHel-big.2008.Areadabilitycheckerwithsupervisedlearningusingdeepsyntacticandsemanticindica-tors.InTomaˇzErjavecandJernejaˇZganecGros,editors,Proceedingsofthe11thInternationalMulti-conference:InformationSociety—IS2008—LanguageTechnologies,pages92–97,Ljubljana,Slovenia.